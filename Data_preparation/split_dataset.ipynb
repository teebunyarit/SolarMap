{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad078f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afbd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''''''\n",
    "\n",
    "Function: train_test_split(df, test_size=0.2, random_state=42, split_by_k=True)\n",
    "\n",
    "Inputs:\n",
    "\n",
    "df: The input dataframe containing the data to be split.\n",
    "test_size: The proportion of the data to be allocated for testing. It is typically expressed as a decimal value between 0 and 1.\n",
    "random_state: An optional parameter that sets the random seed for reproducibility. It ensures the same data split is obtained when the function is executed multiple times with the same random seed.\n",
    "split_by_k: A boolean flag indicating whether the data should be split based on the clear-sky index criteria.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "Training dataframe: The dataframe containing the data for training.\n",
    "Testing dataframe: The dataframe containing the data for testing.\n",
    "\n",
    "The function performs the data split by shuffling the data from three sets based on the clear-sky index criteria:\n",
    "\n",
    "Set i) contains data points where the clear-sky index (k) is greater than 0.6.\n",
    "Set ii) contains data points where the clear-sky index is between 0.3 and 0.6 (inclusive).\n",
    "Set iii) contains data points where the clear-sky index is less than or equal to 0.3.\n",
    "\n",
    "The function then splits the shuffled data into training and testing sets according to the specified test size.\n",
    "\n",
    "'''''''''\n",
    "\n",
    "\n",
    "def train_test_split(df, test_size=0.2, random_state=42, split_by_k = True):\n",
    "        df['date'] = df.index.date\n",
    "        INDEX = df[['site_name','k']].copy()\n",
    "        INDEX['date']= INDEX.index.date\n",
    "        INDEX = INDEX.groupby(by=[df.index.date,'site_name']).mean()\n",
    "        INDEX.reset_index(level=1, inplace=True)\n",
    "        \n",
    "        if split_by_k :\n",
    "            klow = INDEX[INDEX.k<=0.3]\n",
    "            kmed = INDEX[(INDEX.k>0.3) & (INDEX.k<=0.6)]\n",
    "            khigh =  INDEX[(INDEX.k>0.6)]\n",
    "            klow_test = klow.sample(frac=test_size,random_state=random_state)\n",
    "            kmed_test = kmed.sample(frac=test_size,random_state=random_state)\n",
    "            khigh_test = khigh.sample(frac=test_size,random_state=random_state)\n",
    "            dg_test = pd.concat([klow_test, kmed_test, khigh_test])\n",
    "\n",
    "        else:\n",
    "            dg_test = INDEX.sample(frac=test_size, random_state = random_state)\n",
    "            \n",
    "        dg_test.reset_index(inplace=True)\n",
    "        dg_test = dg_test.rename(columns={'index':'date'})\n",
    "        dg_test = dg_test.drop(columns = ['k'])\n",
    "        dg_test = df.reset_index().merge(dg_test,on=['date','site_name']).set_index('Datetime')\n",
    "        dg_train = pd.concat([df,dg_test]).drop_duplicates(keep=False)\n",
    "        dg_train.drop(columns=['date'], inplace =True); dg_test.drop(columns=['date'],inplace =True)\n",
    "        \n",
    "        return dg_train, dg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAN_FOLDER = 'C:\\\\Users\\\\Tee\\\\senior_project\\\\src\\\\SolarMap\\\\DataAndResult\\\\training_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7130fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated 'separated_DATASET_cloudmask.csv'\n",
    "\n",
    "CM_DATA = 'DATASET_cloudmask.csv'\n",
    "df = pd.read_csv(os.path.join(TRIAN_FOLDER,CM_DATA),parse_dates=['Datetime'],index_col='Datetime')\n",
    "dg_train, dg_test = train_test_split(df, test_size=0.2, random_state=42, split_by_k = True)\n",
    "proc = pd.concat([dg_train, dg_test])\n",
    "proc.to_csv('separated_DATASET_cloudmask.csv') # export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10d8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated 'separated_DATASET_ch1_overview.csv'\n",
    "\n",
    "OV_DATA = 'DATASET_ch1_overview.csv'\n",
    "df = pd.read_csv(os.path.join(TRIAN_FOLDER,OV_DATA),parse_dates=['Datetime'],index_col='Datetime')\n",
    "dg_train, dg_test = train_test_split(df, test_size=0.2, random_state=42, split_by_k = True)\n",
    "proc = pd.concat([dg_train, dg_test])\n",
    "proc.to_csv('separated_DATASET_ch1_overview.csv') # export data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
