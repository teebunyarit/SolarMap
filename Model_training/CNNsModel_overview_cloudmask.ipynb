{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a3f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Add, AveragePooling2D, Concatenate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import concatenate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60f244",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d49bd3",
   "metadata": {},
   "source": [
    "Read me !! : you can pass this section if you have a data 'Image_lag10dataset_2layers.csv' and 'Attribute_lag10dataset_2layers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d602b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load croped_img cloud mask dataset which contain 0-255 pixel with site and datetime\n",
    "Image_CM = pd.read_csv('/Users/khunnoot/Downloads/croped_img.csv',parse_dates=True,index_col='datetime')\n",
    "Image_CM.drop(columns = ['Unnamed: 0.1','Unnamed: 0'], inplace = True)\n",
    "Image_CM.index = Image_CM.index + pd.DateOffset(minutes=30) # + 30 min because of the lag time of Himawari images\n",
    "Image_CM = Image_CM.reset_index()\n",
    "Image_CM['datetime']= Image_CM['datetime'].astype(str)\n",
    "\n",
    "#load croped_img RBG dataset which contain 0-255 pixel with site and datetime\n",
    "Image_RGB = pd.read_csv('/Users/khunnoot/Downloads/cropped_image_color.csv',usecols=lambda column: column != 'Unnamed: 0',parse_dates=True,index_col='datetime')\n",
    "Image_RGB.index = Image_RGB.index + pd.DateOffset(minutes=30)\n",
    "Image_RGB = Image_RGB.reset_index()\n",
    "Image_RGB['datetime']= Image_RGB['datetime'].astype(str)\n",
    "\n",
    "#keep only red channel\n",
    "col_delete = []\n",
    "for i in range(256,768):\n",
    "    col_delete.append(str(i))\n",
    "Image_RGB.drop(columns=col_delete,inplace=True)\n",
    "Image_RGB\n",
    "\n",
    "#merge cloud mask layer and red channel layer in 'Image_CM_CHRED'\n",
    "Image_CM_CHRED = pd.merge(Image_CM,Image_RGB,on=['datetime','site'],how='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 'DATASET_CHRED_LAG10' & 'DATASET_CM_LAG10'\n",
    "RED_ATT = pd.read_csv('/Users/khunnoot/Downloads/DATASET_CHRED_LAG10.csv')\n",
    "CM_ATT = pd.read_csv('/Users/khunnoot/Downloads/DATASET_CM_LAG10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename data\n",
    "RED_ATT = RED_ATT.rename(columns={'Datetime':'datetime','site_name':'site'})\n",
    "RED_ATT['datetime']=pd.to_datetime(RED_ATT.datetime)\n",
    "RED_ATT['datetime']=RED_ATT['datetime'].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "CM_ATT = CM_ATT.rename(columns={'Datetime':'datetime','site_name':'site'})\n",
    "CM_ATT['datetime']=pd.to_datetime(CM_ATT.datetime)\n",
    "CM_ATT['datetime']=CM_ATT['datetime'].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "RED_ATT = RED_ATT[['datetime','site','Iclr','I','k','HR','CI0','CI1']].copy()\n",
    "RED_ATT.rename(columns={'CI0':'CI0_ov','CI1':'CI1_ov'},inplace=True)\n",
    "\n",
    "CM_ATT = CM_ATT[['datetime','site','Iclr','I','k','HR','CI0','CI1']].copy()\n",
    "CM_ATT.rename(columns={'CI0':'CI0_cm','CI1':'CI1_cm'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c4f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge attribute(ATT) from cloud mask channel and red channel \n",
    "ATT = pd.merge(CM_ATT[['datetime','site','CI0_cm','CI1_cm']],RED_ATT,on=['datetime','site'],how='inner')\n",
    "\n",
    "#keep the intersec dataset from ATT and Images dataset\n",
    "Image_lag10dataset_2layers = pd.merge(ATT[['datetime','site','I','Iclr','k']],Image_CM_CHRED,on=['datetime','site'],how='inner')\n",
    "Attribute_lag10dataset_2layers = pd.merge(ATT,Image_CM_CHRED[['datetime','site']],on=['datetime','site'],how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set datetime index\n",
    "Image_lag10dataset_2layers['datetime'] = pd.to_datetime(Image_lag10dataset_2layers.datetime)\n",
    "Image_lag10dataset_2layers.set_index('datetime',inplace=True)\n",
    "Image_lag10dataset_2layers.dropna(inplace=True)\n",
    "\n",
    "Attribute_lag10dataset_2layers['datetime'] = pd.to_datetime(Attribute_lag10dataset_2layers.datetime)\n",
    "Attribute_lag10dataset_2layers.set_index('datetime',inplace=True)\n",
    "Attribute_lag10dataset_2layers.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe\n",
    "Image_lag10dataset_2layers.to_csv('Image_lag10dataset_2layers.csv')\n",
    "Attribute_lag10dataset_2layers.to_csv('Attribute_lag10dataset_2layers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a12e0",
   "metadata": {},
   "source": [
    "# Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a29f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Directory = '/Users/khunnoot/Desktop/year4/senior_project/jupyter_notebook'\n",
    "CNNsDataframe = 'Image_lag10dataset_2layers.csv'\n",
    "AtributeDataframe = 'Attribute_lag10dataset_2layers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "347ee982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(Directory, CNNsDataframe),parse_dates=True,index_col='datetime')\n",
    "ATT = pd.read_csv(os.path.join(Directory, AtributeDataframe),parse_dates=True,index_col='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243e31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63910, 516)\n",
      "(63910, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(ATT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def81cec",
   "metadata": {},
   "source": [
    "# Split data by k condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4596e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define split data by using clear-sky index condition\n",
    "def train_test_splits(df, test_size=0.2, random_state=42, split_by_k = True):\n",
    "        df['date'] = df.index.date\n",
    "        INDEX = df[['site','k']].copy()\n",
    "        INDEX['date']= INDEX.index.date\n",
    "        INDEX = INDEX.groupby(by=[df.index.date,'site']).mean()\n",
    "        INDEX.reset_index(level=1, inplace=True)\n",
    "        \n",
    "        if split_by_k :\n",
    "            klow = INDEX[INDEX.k<=0.3]\n",
    "            kmed = INDEX[(INDEX.k>0.3) & (INDEX.k<=0.6)]\n",
    "            khigh =  INDEX[(INDEX.k>0.6)]\n",
    "            klow_test = klow.sample(frac=test_size,random_state=random_state)\n",
    "            kmed_test = kmed.sample(frac=test_size,random_state=random_state)\n",
    "            khigh_test = khigh.sample(frac=test_size,random_state=random_state)\n",
    "            X_test = pd.concat([klow_test, kmed_test, khigh_test])\n",
    "\n",
    "        else:\n",
    "            X_test = INDEX.sample(frac=test_size, random_state = random_state)\n",
    "            \n",
    "        X_test.reset_index(inplace=True)\n",
    "        X_test = X_test.rename(columns={'index':'date'})\n",
    "        X_test = X_test.drop(columns = ['k'])\n",
    "        X_test = df.reset_index().merge(X_test,on=['date','site']).set_index('datetime')\n",
    "        X_train = pd.concat([df,X_test]).drop_duplicates(keep=False)\n",
    "        X_train.drop(columns=['date'],inplace = True); X_test.drop(columns=['date'],inplace = True)\n",
    "        \n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1275426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "train_data, test_data = train_test_splits(df, test_size=0.2, random_state=42, split_by_k = True)\n",
    "train_ATT, test_ATT = train_test_splits(ATT, test_size=0.2, random_state=42, split_by_k = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533cd9e",
   "metadata": {},
   "source": [
    "# Cloud2K Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud2K_name = ['Cloud2Kv1','Cloud2Kv2','Cloud2Kv3','Cloud2Kv4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resblock(x, kernelsize, filters):\n",
    "    fx = layers.Conv2D(filters, kernelsize, padding='same')(x)\n",
    "    fx = layers.BatchNormalization()(fx)\n",
    "    act1 = layers.Activation(activation='relu')(fx)\n",
    "    fx = layers.Conv2D(filters, kernelsize, padding='same')(act1)\n",
    "    out = layers.Add()([x,fx])\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.ReLU()(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3329b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cloud2K_list = []\n",
    "# Define the CNN architecture\n",
    "input_shape = (16, 16, 2)\n",
    "img_inputs = keras.Input(shape=input_shape)\n",
    "conv1 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(img_inputs)\n",
    "conv2 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv2)\n",
    "flatten_cnn = layers.Flatten()(pool1)\n",
    "dense1 = layers.Dense(16, activation='relu')(flatten_cnn)\n",
    "dense2 = layers.Dense(8, activation='relu')(dense1)\n",
    "outputs = layers.Dense(1)(dense2)\n",
    "Cloud2Kv1 = keras.Model(inputs=img_inputs, outputs=outputs, name=\"Cloud2Kv1\")\n",
    "Cloud2K_list.append(Cloud2Kv1)\n",
    "Cloud2Kv1.summary()\n",
    "\n",
    "# Define the CNN architecture\n",
    "input_shape = (16, 16, 2)\n",
    "img_inputs = keras.Input(shape=input_shape)\n",
    "conv1 = layers.Conv2D(32, kernel_size=(5, 5), activation='relu',padding='same')(img_inputs)\n",
    "conv2 = layers.Conv2D(32, kernel_size=(5, 5), activation='relu',padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv2)\n",
    "flatten_cnn = layers.Flatten()(pool1)\n",
    "dense1 = layers.Dense(16, activation='relu')(flatten_cnn)\n",
    "dense3 = layers.Dense(8, activation='relu')(dense1)\n",
    "outputs = layers.Dense(1)(dense3)\n",
    "Cloud2Kv2 = keras.Model(inputs=img_inputs, outputs=outputs, name=\"Cloud2Kv2\")\n",
    "Cloud2K_list.append(Cloud2Kv2)\n",
    "Cloud2Kv2.summary()\n",
    "\n",
    "# Define the CNN architecture\n",
    "input_shape = (16, 16, 2)\n",
    "img_inputs = keras.Input(shape=input_shape)\n",
    "conv1 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(img_inputs)\n",
    "conv2 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv2)\n",
    "conv3 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(pool1)\n",
    "conv4 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv3)\n",
    "pool2 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv4)\n",
    "conv5 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(pool2)\n",
    "conv6 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv5)\n",
    "pool3 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv6)\n",
    "flatten_cnn = layers.Flatten()(pool3)\n",
    "dense1 = layers.Dense(64, activation='relu')(flatten_cnn)\n",
    "dense2 = layers.Dense(16, activation='relu')(dense1)\n",
    "outputs = layers.Dense(1)(dense2)\n",
    "Cloud2Kv3 = keras.Model(inputs=img_inputs, outputs=outputs, name=\"Cloud2Kv3\")\n",
    "Cloud2K_list.append(Cloud2Kv3)\n",
    "Cloud2Kv3.summary()\n",
    "\n",
    "# Define the CNN architecture\n",
    "input_shape = (16, 16, 2)\n",
    "img_inputs = keras.Input(shape=input_shape)\n",
    "conv1 = layers.Conv2D(8, (5, 5), padding='same')(img_inputs)\n",
    "batch1 = layers.BatchNormalization()(conv1)\n",
    "act1 = layers.Activation(activation='relu')(batch1)\n",
    "conv2 = layers.Conv2D(8, (5, 5), padding='same')(act1)\n",
    "batch2 = layers.BatchNormalization()(conv2)\n",
    "act2 = layers.Activation(activation='relu')(batch2)\n",
    "pool1 = layers.MaxPooling2D((2, 2),strides=(2,2))(act2)\n",
    "conv3 = layers.Conv2D(16, (1, 1), padding='same')(pool1)\n",
    "batch3 = layers.BatchNormalization()(conv3)\n",
    "act3 = layers.Activation(activation='relu')(batch3)\n",
    "resbox1 = resblock(batch3, (5, 5), 16)\n",
    "resbox2 = resblock(resbox1, (5, 5), 16)\n",
    "resbox3 = resblock(resbox2, (5, 5), 16)\n",
    "pool3 = layers.MaxPooling2D((2, 2),strides=(2,2))(resbox3)\n",
    "conv4 = layers.Conv2D(32, (1, 1), padding='same')(pool3)\n",
    "batch4 = layers.BatchNormalization()(conv4)\n",
    "act4 = layers.Activation(activation='relu')(batch4)\n",
    "resbox4 = resblock(act4, (5, 5), 32)\n",
    "resbox5 = resblock(resbox4, (5, 5), 32)\n",
    "resbox6 = resblock(resbox5, (5, 5), 32)\n",
    "pool4 = layers.AveragePooling2D((4, 4))(resbox6)\n",
    "flatten_cnn = layers.Flatten()(pool4)\n",
    "dense1 = layers.Dense(32,activation='relu')(flatten_cnn)\n",
    "dense2 = layers.Dense(8,activation='relu')(dense1)\n",
    "outputs = layers.Dense(1)(dense1)\n",
    "Cloud2Kv4 = keras.Model(inputs=img_inputs, outputs=outputs, name=\"Cloud2Kv4\")\n",
    "Cloud2K_list.append(Cloud2Kv4)\n",
    "Cloud2Kv4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da42644",
   "metadata": {},
   "source": [
    "# Cloud2I Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e4b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud2I_name = ['Cloud2Iv1','Cloud2Iv2','Cloud2Iv3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07929c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resblock(x, kernelsize, filters):\n",
    "    fx = layers.Conv2D(filters, kernelsize, padding='same')(x)\n",
    "    act1 = layers.Activation(activation='relu')(fx)\n",
    "    fx = layers.Conv2D(filters, kernelsize, padding='same')(act1)\n",
    "    out = layers.Add()([x,fx])\n",
    "    out = layers.ReLU()(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e076a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"Cloud2Iv1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 16, 16, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 16)   816         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 16)   6416        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 8, 8, 16)     0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            42          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 6)            0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1030)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          263936      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           8224        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            33          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 279,467\n",
      "Trainable params: 279,467\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 12:42:12.358138: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-29 12:42:12.358289: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Cloud2Iv2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 16, 16, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 16)   816         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 16)   6416        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 16)    0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 16)     6416        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 16)     6416        ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 16)    0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 16)     6416        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 16)     6416        ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 16)    0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 6)            42          ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 64)           0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 6)            0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 70)           0           ['flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           4544        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 16)           1040        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            17          ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,539\n",
      "Trainable params: 38,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Cloud2Iv3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 16, 16, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 8)    408         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 16, 8)   32          ['conv2d_8[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 16, 16, 8)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 8)    1608        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 8)   32          ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 8)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 8)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 16)     144         ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 16)    64          ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 16)     6416        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 16)     0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 16)     6416        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 16)     0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 8, 8, 16)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 16)     6416        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 8, 8, 16)     0           ['conv2d_13[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 16)     6416        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 8, 8, 16)     0           ['re_lu[0][0]',                  \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 8, 8, 16)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 16)     6416        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 8, 8, 16)     0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 16)     6416        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 8, 8, 16)     0           ['re_lu_1[0][0]',                \n",
      "                                                                  'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 8, 8, 16)     0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 16)    0           ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 4, 4, 32)     544         ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 4, 4, 32)    128         ['conv2d_17[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 4, 4, 32)     25632       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 4, 4, 32)     0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 4, 4, 32)     25632       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 4, 4, 32)     0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 4, 4, 32)     0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 4, 4, 32)     25632       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 4, 4, 32)     0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 4, 4, 32)     25632       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4, 4, 32)     0           ['re_lu_3[0][0]',                \n",
      "                                                                  'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 4, 4, 32)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 4, 4, 32)     25632       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 4, 4, 32)     0           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 4, 4, 32)     25632       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 4, 4, 32)     0           ['re_lu_4[0][0]',                \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 4, 4, 32)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 32)    0           ['re_lu_5[0][0]']                \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 6)            42          ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 32)           0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 6)            0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 38)           0           ['flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 32)           1248        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 8)            264         ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            9           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 196,811\n",
      "Trainable params: 196,683\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Cloud2I_list = []\n",
    "# define CNN model\n",
    "input_shape = (16, 16, 2)\n",
    "img_inputs = keras.Input(shape=input_shape)\n",
    "ATT_input = keras.Input(shape=(6))\n",
    "conv1 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(img_inputs)\n",
    "conv2 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv2)\n",
    "flatten_cnn = layers.Flatten()(pool1)\n",
    "dense1 = layers.Dense(6)(ATT_input) # define MLP model\n",
    "flatten_mlp = layers.Flatten()(dense1)\n",
    "merged = layers.concatenate([flatten_cnn, flatten_mlp]) # combine CNN and MLP\n",
    "dense3 = layers.Dense(256, activation='relu')(merged) \n",
    "dense4 = layers.Dense(32, activation='relu')(dense3)\n",
    "outputs = layers.Dense(1)(dense4)\n",
    "Cloud2Iv1 = keras.Model(inputs=[img_inputs, ATT_input], outputs=outputs, name=\"Cloud2Iv1\")\n",
    "Cloud2I_list.append(Cloud2Iv1)\n",
    "Cloud2Iv1.summary()\n",
    "\n",
    "# define CNN model\n",
    "input_shape = (16, 16, 2)\n",
    "img_inputs = keras.Input(shape=input_shape)\n",
    "ATT_input = keras.Input(shape=(6))\n",
    "conv1 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(img_inputs)\n",
    "conv2 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv1)\n",
    "pool1 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv2)\n",
    "conv3 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(pool1)\n",
    "conv4 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv3)\n",
    "pool2 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv4)\n",
    "conv5 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(pool2)\n",
    "conv6 = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',padding='same')(conv5)\n",
    "pool3 = layers.MaxPooling2D((2, 2),strides=(2,2))(conv6)\n",
    "flatten_cnn = layers.Flatten()(pool3)\n",
    "dense1 = layers.Dense(6)(ATT_input) # define MLP model\n",
    "flatten_mlp = layers.Flatten()(dense1)\n",
    "merged = layers.concatenate([flatten_cnn, flatten_mlp]) # combine CNN and MLP\n",
    "dense3 = layers.Dense(64, activation='relu')(merged)\n",
    "dense4 = layers.Dense(16, activation='relu')(dense3)\n",
    "outputs = layers.Dense(1)(dense4)\n",
    "Cloud2Iv2 = keras.Model(inputs=[img_inputs, ATT_input], outputs=outputs, name=\"Cloud2Iv2\")\n",
    "Cloud2I_list.append(Cloud2Iv2)\n",
    "Cloud2Iv2.summary()\n",
    "\n",
    "\n",
    "# define CNN model\n",
    "input_shape = (16, 16, 2)\n",
    "img_inputs = keras.Input(shape=input_shape)\n",
    "ATT_input = keras.Input(shape=(6))\n",
    "conv1 = layers.Conv2D(8, (5, 5), padding='same')(img_inputs)\n",
    "batch1 = layers.BatchNormalization()(conv1)\n",
    "act1 = layers.Activation(activation='relu')(batch1)\n",
    "conv2 = layers.Conv2D(8, (5, 5), padding='same')(act1)\n",
    "batch2 = layers.BatchNormalization()(conv2)\n",
    "act2 = layers.Activation(activation='relu')(batch2)\n",
    "pool1 = layers.MaxPooling2D((2, 2),strides=(2,2))(act2)\n",
    "conv3 = layers.Conv2D(16, (1, 1), padding='same')(pool1)\n",
    "batch3 = layers.BatchNormalization()(conv3)\n",
    "act3 = layers.Activation(activation='relu')(batch3)\n",
    "resbox1 = resblock(batch3, (5, 5), 16)\n",
    "resbox2 = resblock(resbox1, (5, 5), 16)\n",
    "resbox3 = resblock(resbox2, (5, 5), 16)\n",
    "pool3 = layers.MaxPooling2D((2, 2),strides=(2,2))(resbox3)\n",
    "conv4 = layers.Conv2D(32, (1, 1), padding='same')(pool3)\n",
    "batch4 = layers.BatchNormalization()(conv4)\n",
    "resbox4 = resblock(batch4, (5, 5), 32)\n",
    "resbox5 = resblock(resbox4, (5, 5), 32)\n",
    "resbox6 = resblock(resbox5, (5, 5), 32)\n",
    "pool4 = layers.AveragePooling2D((4, 4))(resbox6)\n",
    "flatten_cnn = layers.Flatten()(pool4)\n",
    "dense1 = layers.Dense(6)(ATT_input) # define MLP model\n",
    "flatten_mlp = layers.Flatten()(dense1)\n",
    "merged = layers.concatenate([flatten_cnn, flatten_mlp])\n",
    "dense2 = layers.Dense(32,activation='relu')(merged)\n",
    "dense3 = layers.Dense(8,activation='relu')(dense2)\n",
    "outputs = layers.Dense(1)(dense3)\n",
    "Cloud2Iv3 = keras.Model(inputs=[img_inputs, ATT_input], outputs=outputs, name=\"Cloud2Iv3\")\n",
    "Cloud2I_list.append(Cloud2Iv3)\n",
    "Cloud2Iv3.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551174c",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Cloud2K model\n",
    "TargetVariable = ['k']\n",
    "Predictors = list(df.columns.drop(['site','k','Iclr','CI0','I','date']))\n",
    " \n",
    "X_train = train_data[Predictors].values.reshape(-1,16,16,2)\n",
    "y_train = train_data[TargetVariable].values\n",
    "X_test = test_data[Predictors].values.reshape(-1,16,16,2)\n",
    "y_test =test_data[TargetVariable].values\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split train and validate set \n",
    "X_train_train, X_valid, y_train_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f972f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile and train the Cloud2K model\n",
    "\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "for index, model in enumerate(Cloud2K_list) :\n",
    "    earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 20, \n",
    "                                        restore_best_weights = True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, min_lr=0.001)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.002)\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = 'mean_absolute_error')\n",
    "    Cloud2K_name[index] = model.fit(X_train_train, y_train_train, epochs = epochs, \n",
    "                        batch_size = batch_size,validation_data = (X_valid, y_valid) ,\n",
    "                        verbose = 1,callbacks = [earlystopping, reduce_lr] ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0398556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save Cloud2K model\n",
    "name = ['Cloud2Kv1','Cloud2Kv2','Cloud2Kv3','Cloud2Kv4']\n",
    "for i,save_model in enumerate(Cloud2K_list):\n",
    "    save_model.save(str(name[i]+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2978dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save loss and val_loss in each epoch to .CSV\n",
    "\n",
    "hist_csv_file = ['hisc2kv1.csv','hisc2kv2.csv','hisc2kv3.csv','hisc2kv4.csv']\n",
    "for i,model in enumerate(Cloud2K_name):\n",
    "    loss = model.history['loss']\n",
    "    val_loss = model.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    valid_loss = pd.DataFrame(dict(epochs = range(len(loss)),\n",
    "                                   loss = model.history['loss'],val_loss = model.history['val_loss']))\n",
    " \n",
    "    with open(hist_csv_file[i], mode='w') as f:\n",
    "        valid_loss.to_csv(f)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f95208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Cloud2I model\n",
    "\n",
    "TargetVariable=['I']\n",
    "Predictors=list(df.columns.drop(['site','k','Iclr','I','date']))\n",
    "\n",
    "X_train=train_data[Predictors].values.reshape(-1,16,16,2)\n",
    "y_train=train_data[TargetVariable].values\n",
    "X_test = test_data[Predictors].values.reshape(-1,16,16,2)\n",
    "y_test =test_data[TargetVariable].values\n",
    "\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "\n",
    "ATT_taget = ['I']\n",
    "ATT_predictors = list(ATT.columns.drop(['I','site','k','date']))\n",
    "X_train_ATT=train_ATT[ATT_predictors].values\n",
    "y_train_ATT=train_ATT[ATT_taget].values\n",
    "X_test_ATT = test_ATT[ATT_predictors].values\n",
    "y_test_ATT =test_ATT[ATT_taget].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split train and validate set \n",
    "X_train_train, X_valid, y_train_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, shuffle = False) \n",
    "X_train_train_ATT, X_val_ATT, y_train_train_ATT, y_val_ATT = train_test_split(X_train_ATT, y_train_ATT, test_size=0.25, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01998315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 12:42:25.499312: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-29 12:42:25.823828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - ETA: 0s - loss: 134.8138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 12:42:36.450325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 12s 10ms/step - loss: 134.8138 - val_loss: 132.8490 - lr: 0.0020\n",
      "Epoch 2/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 124.0716 - val_loss: 127.0184 - lr: 0.0020\n",
      "Epoch 3/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 122.3013 - val_loss: 123.6381 - lr: 0.0020\n",
      "Epoch 4/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 120.9858 - val_loss: 120.4670 - lr: 0.0020\n",
      "Epoch 5/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 121.0447 - val_loss: 119.7551 - lr: 0.0020\n",
      "Epoch 6/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 120.2051 - val_loss: 119.8336 - lr: 0.0020\n",
      "Epoch 7/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 119.9259 - val_loss: 121.4578 - lr: 0.0020\n",
      "Epoch 8/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 119.4674 - val_loss: 122.5369 - lr: 0.0020\n",
      "Epoch 9/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 119.0956 - val_loss: 120.8379 - lr: 0.0020\n",
      "Epoch 10/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 118.8612 - val_loss: 123.9414 - lr: 0.0020\n",
      "Epoch 11/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 116.8432 - val_loss: 117.9847 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 116.4571 - val_loss: 117.4121 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 116.3885 - val_loss: 118.5984 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 115.8250 - val_loss: 121.3909 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 115.7022 - val_loss: 116.6156 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 115.3410 - val_loss: 116.3421 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 115.1217 - val_loss: 116.2742 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 114.7802 - val_loss: 115.7558 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 114.3561 - val_loss: 116.1652 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 114.2290 - val_loss: 116.3473 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 113.9331 - val_loss: 115.5111 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 113.3209 - val_loss: 116.6431 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 112.9691 - val_loss: 119.8475 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 112.9456 - val_loss: 114.7176 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 112.5652 - val_loss: 115.0459 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 112.0345 - val_loss: 115.0122 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 111.7104 - val_loss: 117.2293 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 111.4370 - val_loss: 115.4508 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 111.1081 - val_loss: 118.0832 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 110.8103 - val_loss: 114.4463 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 110.3456 - val_loss: 117.1290 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 110.4242 - val_loss: 115.2701 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 109.7696 - val_loss: 115.9161 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 109.3503 - val_loss: 114.2270 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 108.8960 - val_loss: 113.8986 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 108.6748 - val_loss: 113.9037 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 108.2383 - val_loss: 113.5854 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 107.8432 - val_loss: 115.1741 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 107.3249 - val_loss: 113.9446 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 107.1959 - val_loss: 115.4303 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 106.9385 - val_loss: 114.5691 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 106.3038 - val_loss: 116.1214 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 105.9796 - val_loss: 113.2907 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 105.5779 - val_loss: 115.2350 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 105.1419 - val_loss: 114.5162 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 104.8849 - val_loss: 116.0568 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 104.4599 - val_loss: 113.5365 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 104.1514 - val_loss: 115.3979 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 103.6427 - val_loss: 116.7829 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 103.2532 - val_loss: 113.5846 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 102.8025 - val_loss: 113.5146 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 102.1538 - val_loss: 113.3534 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 101.9559 - val_loss: 117.2404 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 101.7121 - val_loss: 114.4861 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 101.1840 - val_loss: 113.7060 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 100.7026 - val_loss: 113.6917 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 100.1986 - val_loss: 116.9833 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 99.8466 - val_loss: 113.3332 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 99.3090 - val_loss: 113.7600 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 99.0573 - val_loss: 113.4158 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 98.7202 - val_loss: 114.1763 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 98.2429 - val_loss: 114.2826 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 97.7953 - val_loss: 114.4950 - lr: 0.0010\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 12:54:41.240081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - ETA: 0s - loss: 138.7154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 12:54:55.480022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 16s 13ms/step - loss: 138.7154 - val_loss: 125.1665 - lr: 0.0020\n",
      "Epoch 2/500\n",
      "1200/1200 [==============================] - 16s 14ms/step - loss: 124.6573 - val_loss: 129.6932 - lr: 0.0020\n",
      "Epoch 3/500\n",
      "1200/1200 [==============================] - 17s 14ms/step - loss: 123.9602 - val_loss: 125.9672 - lr: 0.0020\n",
      "Epoch 4/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 122.6167 - val_loss: 122.6398 - lr: 0.0020\n",
      "Epoch 5/500\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 122.1876 - val_loss: 120.7513 - lr: 0.0020\n",
      "Epoch 6/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 120.9560 - val_loss: 127.7067 - lr: 0.0020\n",
      "Epoch 7/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 120.6842 - val_loss: 123.0110 - lr: 0.0020\n",
      "Epoch 8/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 120.1163 - val_loss: 121.8017 - lr: 0.0020\n",
      "Epoch 9/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 119.7847 - val_loss: 132.1118 - lr: 0.0020\n",
      "Epoch 10/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 119.3234 - val_loss: 119.6512 - lr: 0.0020\n",
      "Epoch 11/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 119.4065 - val_loss: 125.3827 - lr: 0.0020\n",
      "Epoch 12/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 118.7347 - val_loss: 118.6991 - lr: 0.0020\n",
      "Epoch 13/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 118.4314 - val_loss: 118.1915 - lr: 0.0020\n",
      "Epoch 14/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 117.9592 - val_loss: 121.6757 - lr: 0.0020\n",
      "Epoch 15/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 117.7869 - val_loss: 122.5194 - lr: 0.0020\n",
      "Epoch 16/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 117.3560 - val_loss: 119.5144 - lr: 0.0020\n",
      "Epoch 17/500\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 116.9332 - val_loss: 117.2950 - lr: 0.0020\n",
      "Epoch 18/500\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 117.1060 - val_loss: 118.4110 - lr: 0.0020\n",
      "Epoch 19/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 116.7217 - val_loss: 116.9672 - lr: 0.0020\n",
      "Epoch 20/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 116.2643 - val_loss: 117.3559 - lr: 0.0020\n",
      "Epoch 21/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 116.1679 - val_loss: 120.6552 - lr: 0.0020\n",
      "Epoch 22/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 115.6578 - val_loss: 117.4138 - lr: 0.0020\n",
      "Epoch 23/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 115.0961 - val_loss: 117.5732 - lr: 0.0020\n",
      "Epoch 24/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 114.6712 - val_loss: 116.5950 - lr: 0.0020\n",
      "Epoch 25/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 114.7623 - val_loss: 116.3339 - lr: 0.0020\n",
      "Epoch 26/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 114.1878 - val_loss: 117.6162 - lr: 0.0020\n",
      "Epoch 27/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 113.7661 - val_loss: 116.0232 - lr: 0.0020\n",
      "Epoch 28/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 113.3159 - val_loss: 115.6297 - lr: 0.0020\n",
      "Epoch 29/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 112.8775 - val_loss: 115.7393 - lr: 0.0020\n",
      "Epoch 30/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 113.0257 - val_loss: 116.3507 - lr: 0.0020\n",
      "Epoch 31/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 112.1889 - val_loss: 117.1848 - lr: 0.0020\n",
      "Epoch 32/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 112.0779 - val_loss: 116.0687 - lr: 0.0020\n",
      "Epoch 33/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 111.9982 - val_loss: 118.9302 - lr: 0.0020\n",
      "Epoch 34/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 108.8237 - val_loss: 115.4142 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 108.1279 - val_loss: 115.2775 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 107.1467 - val_loss: 115.6658 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 106.5865 - val_loss: 117.7720 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 105.8712 - val_loss: 115.1982 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 105.1739 - val_loss: 115.5768 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 104.7398 - val_loss: 116.5620 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 104.1867 - val_loss: 115.5491 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 103.4142 - val_loss: 116.0900 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 102.7748 - val_loss: 115.8805 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 102.3842 - val_loss: 118.0021 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 101.7610 - val_loss: 117.0404 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 101.3544 - val_loss: 115.2868 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 100.8390 - val_loss: 118.2332 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 100.4149 - val_loss: 117.0173 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 99.9091 - val_loss: 115.1835 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 99.3858 - val_loss: 115.7782 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 98.6503 - val_loss: 115.9897 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 98.5718 - val_loss: 115.7645 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 98.2102 - val_loss: 115.6192 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 97.0889 - val_loss: 116.0194 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 96.9012 - val_loss: 116.2729 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 96.4696 - val_loss: 115.8176 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 96.1531 - val_loss: 117.4091 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 95.6925 - val_loss: 117.2262 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 95.1022 - val_loss: 117.5766 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 94.7557 - val_loss: 117.1929 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 94.6529 - val_loss: 116.0725 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 93.7964 - val_loss: 116.6618 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 93.3543 - val_loss: 117.0670 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 93.1944 - val_loss: 116.3213 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 92.8425 - val_loss: 118.7050 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 92.5949 - val_loss: 116.6457 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 92.1180 - val_loss: 117.2878 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 91.8689 - val_loss: 116.2593 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 91.3135 - val_loss: 117.6801 - lr: 0.0010\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 13:12:41.444217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - ETA: 0s - loss: 132.4832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 13:13:09.838484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 32s 25ms/step - loss: 132.4832 - val_loss: 125.4141 - lr: 0.0020\n",
      "Epoch 2/500\n",
      "1200/1200 [==============================] - 28s 24ms/step - loss: 125.4414 - val_loss: 126.8560 - lr: 0.0020\n",
      "Epoch 3/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 124.7208 - val_loss: 130.5356 - lr: 0.0020\n",
      "Epoch 4/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 123.5985 - val_loss: 123.9198 - lr: 0.0020\n",
      "Epoch 5/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 123.4482 - val_loss: 120.9431 - lr: 0.0020\n",
      "Epoch 6/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 123.0008 - val_loss: 142.0422 - lr: 0.0020\n",
      "Epoch 7/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 122.7667 - val_loss: 122.6909 - lr: 0.0020\n",
      "Epoch 8/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 122.0770 - val_loss: 123.2996 - lr: 0.0020\n",
      "Epoch 9/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 121.9120 - val_loss: 120.9929 - lr: 0.0020\n",
      "Epoch 10/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 121.0073 - val_loss: 132.1560 - lr: 0.0020\n",
      "Epoch 11/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 120.0387 - val_loss: 118.6920 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 119.6363 - val_loss: 119.2736 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 119.1805 - val_loss: 119.0176 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 118.8584 - val_loss: 136.3763 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 118.6244 - val_loss: 121.6026 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 118.6888 - val_loss: 118.8580 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 117.7946 - val_loss: 121.4411 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 118.2815 - val_loss: 118.9584 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 117.8484 - val_loss: 120.9810 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1200/1200 [==============================] - 29s 24ms/step - loss: 117.1044 - val_loss: 117.0662 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 117.1407 - val_loss: 117.3151 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 117.5218 - val_loss: 118.0643 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 116.6827 - val_loss: 120.1311 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 116.8195 - val_loss: 117.2792 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 116.2190 - val_loss: 119.3357 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 116.5453 - val_loss: 116.1930 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 116.1733 - val_loss: 116.0507 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 115.7686 - val_loss: 117.1743 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 115.7365 - val_loss: 117.2069 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 115.4389 - val_loss: 116.5793 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 115.2169 - val_loss: 116.3556 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 114.7634 - val_loss: 117.7908 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 114.7839 - val_loss: 117.2178 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 114.5288 - val_loss: 117.6674 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 114.1179 - val_loss: 119.8038 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 113.9184 - val_loss: 118.7160 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 113.8383 - val_loss: 117.5829 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 113.4267 - val_loss: 116.5825 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "1200/1200 [==============================] - 28s 23ms/step - loss: 113.2748 - val_loss: 117.9592 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 112.9305 - val_loss: 116.8782 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 112.4290 - val_loss: 117.6674 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 112.1890 - val_loss: 119.2906 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 111.9196 - val_loss: 119.4824 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 111.2994 - val_loss: 116.7813 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 111.6222 - val_loss: 117.3124 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 110.8198 - val_loss: 116.4943 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "1200/1200 [==============================] - 27s 23ms/step - loss: 110.6069 - val_loss: 119.4740 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the Cloud2I model\n",
    "\n",
    "\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "batch_size = 32\n",
    "epochs=500\n",
    "\n",
    "\n",
    "for index,model in enumerate(Cloud2I_list) :\n",
    "    earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 20, \n",
    "                                        restore_best_weights = True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.002)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "    Cloud2I_name[index]=model.fit([X_train_train, X_train_train_ATT], y_train_train, epochs=epochs, \n",
    "                              batch_size = batch_size, validation_data=([X_valid, X_val_ATT], y_valid) ,\n",
    "                              verbose=1,callbacks =[earlystopping,reduce_lr] ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31649c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save Cloud2I model\n",
    "\n",
    "name = ['Cloud2Iv1','Cloud2Iv2','Cloud2Iv3']\n",
    "for i,save_model in enumerate(Cloud2I_list):\n",
    "    save_model.save(str(name[i]+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04891dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#save loss and val_loss in each epoch to .CSV\n",
    "\n",
    "hist_csv_file = ['hisc2Iv1.csv','hisc2Iv2.csv','hisc2Iv3.csv']\n",
    "for i,model in enumerate(Cloud2I_name):\n",
    "    loss = model.history['loss']\n",
    "    val_loss = model.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "\n",
    "    valid_loss = pd.DataFrame(dict(epochs = range(len(loss)),loss = model.history['loss'],\n",
    "                                   val_loss = model.history['val_loss']))\n",
    "    \n",
    "    with open(hist_csv_file[i], mode='w') as f:\n",
    "        valid_loss.to_csv(f)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0c586",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.listdir('/Users/khunnoot/Desktop/year4/senior_project/jupyter_notebook')\n",
    "\n",
    "file_Cloud2K = ['Cloud2Kv1.h5','Cloud2Kv2.h5','Cloud2Kv3.h5','Cloud2Kv4.h5']\n",
    "file_Cloud2I = ['Cloud2Iv1.h5','Cloud2Iv2.h5','Cloud2Iv3.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da3f5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def model(file): #load model and keep in the list \n",
    "    model = []\n",
    "    for name in file:\n",
    "        model.append(load_model(os.path.join(Directory,name)))\n",
    "    return model \n",
    "def get_name(file) : # get name of each model and add in the list\n",
    "    name = []\n",
    "    for i in file :\n",
    "        i = i[:-3]\n",
    "        name.append(i)\n",
    "    return name \n",
    "def k_to_I(df,k_columns,I_columns): #change estimated k to estimated I\n",
    "    col_name = []\n",
    "    for i,c in enumerate(k_columns):\n",
    "        name = 'I_'+c\n",
    "        df=df.assign( col = lambda x: (x[c] * x['Iclr']))\n",
    "        df.rename(columns={'col':name},inplace=True)\n",
    "        col_name.append(name)\n",
    "    for i in I_columns :\n",
    "        name = 'I_' + i\n",
    "        col_name.append(name)\n",
    "    return df[['site','I']+col_name]\n",
    "def AE(df,I_columns): #generate absolute error\n",
    "    name = []\n",
    "    for i,c in enumerate(I_columns):\n",
    "        AE_name = 'AE_'+c[2:]\n",
    "        df=df.assign( col = lambda x: abs(x[c] - x['I']))\n",
    "        df.rename(columns={'col':AE_name},inplace=True)\n",
    "        SE_name = 'SE_'+c[2:]\n",
    "        df=df.assign( col = lambda x: (x[c] - x['I'])**2)\n",
    "        df.rename(columns={'col':SE_name},inplace=True)\n",
    "        name.append(AE_name)\n",
    "    return df[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Cloud2K = model(file_Cloud2K)\n",
    "model_Cloud2I = model(file_Cloud2I)\n",
    "Cloud2K = get_name(file_Cloud2K)\n",
    "Cloud2I =  get_name(file_Cloud2I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a46bfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_model generate the model prediction when the input is 'df,ATT' = dataframe, Cloud2Kname and Cloud2Iname is \n",
    "# is list of name of each models , model_Cloud2K and model_Cloud2I is list of each models \n",
    "# if you do not have any model, you can insert only '[]'\n",
    "\n",
    "def pred_model(df, ATT, Cloud2Kname, Cloud2Iname, model_Cloud2K, model_Cloud2I):\n",
    "    #train test split\n",
    "    train_data, test_data = train_test_splits(df, test_size=0.2, random_state=42, split_by_k = True)\n",
    "    train_ATT, test_ATT = train_test_splits(ATT, test_size=0.2, random_state=42, split_by_k = True)\n",
    "\n",
    "    #for map k\n",
    "    TargetVariable=['k']\n",
    "    Predictors=list(df.columns.drop(['site','k','Iclr','I','date']))\n",
    "    X_train=train_data[Predictors].values.reshape(-1,16,16,2)\n",
    "    y_train=train_data[TargetVariable].values\n",
    "    X_test = test_data[Predictors].values.reshape(-1,16,16,2)\n",
    "    y_test =test_data[TargetVariable].values\n",
    "    X_train=X_train/255\n",
    "    X_test=X_test/255\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    #split train and validate set \n",
    "    X_train_train, X_valid, y_train_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, shuffle = False) \n",
    "\n",
    "    ## run train test split of model map k\n",
    "    result=test_data[['site','Iclr','I']+TargetVariable].copy()\n",
    "    for i,model in enumerate(model_Cloud2K):\n",
    "        k_pred=model.predict(X_test)\n",
    "        result['k_predict']=k_pred\n",
    "        result=result.rename(columns={'k_predict':Cloud2Kname[i]})\n",
    "\n",
    "    #for map I\n",
    "\n",
    "    TargetVariable=['I']\n",
    "    Predictors=list(df.columns.drop(['site','k','Iclr','I','date']))\n",
    "    X_train=train_data[Predictors].values.reshape(-1,16,16,2)\n",
    "    y_train=train_data[TargetVariable].values\n",
    "    X_test = test_data[Predictors].values.reshape(-1,16,16,2)\n",
    "    y_test =test_data[TargetVariable].values\n",
    "    X_train=X_train/255\n",
    "    X_test=X_test/255\n",
    "\n",
    "    ATT_taget = ['I']\n",
    "    ATT_predictors = list(ATT.columns.drop(['I','site','k','date']))\n",
    "    X_train_ATT = train_ATT[ATT_predictors].values\n",
    "    y_train_ATT = train_ATT[ATT_taget].values\n",
    "    X_test_ATT = test_ATT[ATT_predictors].values\n",
    "    y_test_ATT = test_ATT[ATT_taget].values\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    #split train and validate set \n",
    "    X_train_train, X_valid, y_train_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, shuffle = False) \n",
    "    X_train_train_ATT, X_val_ATT, y_train_train_ATT, y_val_ATT = train_test_split(X_train_ATT, y_train_ATT, test_size=0.25, shuffle = False)\n",
    "\n",
    "    ## run train test split of model map I\n",
    "    for i,model in enumerate(model_Cloud2I):\n",
    "        I_pred=model.predict([X_test,X_test_ATT])\n",
    "        result['I_predict']=I_pred\n",
    "        result=result.rename(columns={'I_predict':'I_'+Cloud2Iname[i]})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b32b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pred_model(df,ATT,Cloud2K, Cloud2I, model_Cloud2K, model_Cloud2I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbee7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to estemated I \n",
    "Ihat = k_to_I(output, Cloud2K, Cloud2I)\n",
    "Ihat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ebc3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ihat.to_csv('Ihat_2layer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a21e906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_Cloud2Iv1_lag10    115.373089\n",
       "AE_Cloud2Iv2_lag10    118.127025\n",
       "AE_Cloud2Iv3_lag10    117.750717\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_col = Ihat.drop(columns=['site','I'])\n",
    "err_AE = AE(Ihat,I_col)\n",
    "err_AE.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
